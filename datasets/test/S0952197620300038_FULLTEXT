10.1016/j.engappai.2020.103478

FULLTEXT

TITLE

Learning the representation of raw acoustic emission signals by direct generative modelling and its use in chronology-based clusters identification

SECTION

Introduction

PARAGRAPH

Monitoring the formation and propagation of damages in materials is of paramount importance for ensuring the availability and safety of industrial equipment in many application fields.

The non-destructive technique called acoustic emission (AE) is widely used for that purpose.

The terms around the AE technique were made uniform in the ASTM standard E1316 (Anon., 2019a, 2016).

The principle of the AE technique is the detection of the subnanometric displacements of the surface of a material induced by the propagation of an elastic wave generated by a sudden and permanent change in the integrity of a material.

Permanent changes can, for example, be related to plasticity and cracks at various scales.

The mechanical wave is then transformed into a voltage signal by an AE sensor (usually piezo-electric based).

The frequency content of the wave may vary, and it is quite common in AE literature to use preamplifiers including a bandpass filter in the range 20 kHz–1 MHz.

PARAGRAPH

The AE technique has been applied in Structural Health Monitoring (SHM) (Muravin, 2000; Muravin et al., 2010; Ono and Gallego, 2012; Ono, 2018; Farrar and Worden, 2013) since the progression of the signature of those mechanical waves can provide useful insights about the behaviour of a material during loading.

It was used, for example, to detect, localise, identify and monitor AE sources in rocks (Hohl et al., 0000), concrete structures (Behnia et al., 2014), pressure vessels (Gorman, 2011), rolling bearings (Aye and Heyns, 2017; Martin-Del-Campo and Sandin, 2017), grinding wheels (Liao et al., 2006, 2007, 2008; Liao, 2010), tool wear (Wang and Feng, 2013) and in tribology (Taura and Nakayama, 2018; Del Campo et al., 2019).

PARAGRAPH

The sensitivity of the AE sensors makes this technique suitable for detecting damages at various scales as encountered in complex heterogeneous materials made of various constituents with different damage kinetics.

For example, in composite materials such as Carbon-Fibre Reinforced Plastics (CFRP), multiscale damages can occur such as matrix cracking, fibre breakage, debonding or ply delamination which can be detected using the AE technique (Ono and Gallego, 2012).

PARAGRAPH

Detecting and identifying damages by the AE technique requires to develop an efficient pattern recognition chain able to tackle the specificities of AE signals:

PARAGRAPH

In addition to those specificities, the variability of the initial damage state of materials and structures due to the manufacturing process make difficult the generalisation of conclusions between papers (Chandarana, 2019).

SECTION

The standard approach to interpret AE signals

PARAGRAPH

Unknowns behind the generation process of AE signals and the modification of those signals along the propagation path until the sensors account for the use and development of unsupervised learning methods to interpret them.

Supervised learning requires to precisely know the source of every AE signal in a dataset, which is possible only for simple configurations.

Unsupervised learning in AE signals relies on a set of steps (described below) which are common in feature-based time-series clustering (Fig. 1 Liao, 2005; Liao, 2007; Fu, 2011).

SECTION

Feature extraction and the need of representation learning

PARAGRAPH

The first step, called feature extraction, generates a feature vector for each AE signal.

Each feature is an axis in a coordinates system that allows to represent all AE signals by a set of common variables.

Without prior knowledge, selecting the correct set of AE features can be challenging and is an active area of research in AE.

A lot of features are generally manually extracted (in Kattis, 2017; Kharrat et al., 2016; Sause, 2016, commonly used features in AE can be found) and a common practice in AE literature is to perform subset selection by wrapping (Sause, 2016) or sequentially (Doan et al., 2015) in order to select a unique subset.

The majority of unsupervised learning methods in AE literature makes use of a unique subset of features.

To our knowledge, only Ramasso et al. (2015) makes use of multiple subsets for clustering AE data.

PARAGRAPH

The use of a unique and manually-extracted low-dimensional feature subset is unlikely to represent AE signals due to the complexity of the underlying physics.

Representation learning from raw data is one solution explored in this paper.

It is based on the estimation of a parametric mapping acting as an encoding function which makes the data easier to interpret.

Numerous examples can be found in supervised machine learning (Bengio et al., 2013; Strisciuglio et al., 2019; Bhatt et al., 2019).

PARAGRAPH

Representation learning has become an active area of research in machine learning with recent deep learning advances.

However, for unsupervised learning, there are much less available methods (Abonyi and Feil, 2007).

Principal components analysis (PCA) is one representation learning approach used in unsupervised learning in AE literature (Godin et al., 2018).

The PCA linearly transforms the original set of features into a new space with orthogonal axes so that the mapping retains as much information as possible in terms of variance.

The first axis of this new coordinates system is given by the eigenvector with the largest eigenvalue computed from the data covariance matrix.

By retaining the largest eigenvalues, the PCA performs an additional feature (and lossy) extraction yielding uncorrelated features.

PARAGRAPH

The PCA relies on several assumptions (quest of a linear combination of features weighted by eigenvectors, orthogonality of axes, maximising the variance, the search of uncorrelated features).

Moreover, the fact that the covariance matrix of the full dataset is used to perform the projection makes the encoding similar for all feature vectors, even though the AE signals are originated from different AE sources.

Additionally, the PCA is a lossy compression procedure which is traditionally applied after a first feature extraction step, itself a lossy one that is performed on raw signals.

PARAGRAPH

Deep autoencoder is another representation learning method used in Abrahimkhanlou et al. (2019) for the localisation of AE events using a single AE sensor.

This recent representation learning method is worth mentioning since it can encode linear and non-linear mapping (Anon., 2019b).

As described in Pimentel et al. (2014, Section 4.1), neural nets and deep encoders were successfully used for anomaly detection and so can be included in the methodology we propose.

SECTION

Clustering

PARAGRAPH

The second step is called clustering and aims at identifying, from features, the discrete latent variables called clusters.

Latent variables practically represent the damage families, unobservable directly but through the AE technique.

PARAGRAPH

We can enumerate two categories of methods used in AE clustering (we consider only multivariate approaches): mono-subset approaches (Doctor et al., 1979; Godin et al., 2004; Sause, 2016; Sawan et al., 2015) and consensus clustering (using multiple subsets) (Ramasso et al., 2015).

It was shown in other applications that consensus clustering is able to discover useful patterns for complex data (Wang et al., 2015; Yang et al., 2016; Lin et al., 2018) by exploring different subspaces of the original feature space.

In each category, different clustering methods have been used such as Kmeans, Fuzzy-C-means, Gustafson–Kessel or Gaussian mixture models.

SECTION

Evaluation

PARAGRAPH

The third step is evaluation, that quantifies the relevance of the clusters identified in the previous step.

Davies–Bouldin and Silhouette indices are among the most used clustering validity indices (Bezdek and Pal, 1998; Kryszczuk and Hurley, 2010; Vendramin et al., 2010; Pakhira et al., 2004; Liao, 2007).

Those indices are often dependent on both clusters and features.

Hence, such methods to evaluate a clustering result make use of feature-level constraints (Wagstaff, 2002).

In contrast, cluster-level constraints (Ge, 2008) aims at selecting a parameterisation according to the fulfilment of some constraints on the partition.

This can be used, for example, to sort partitions of AE signals (Ramasso et al., 2015).

The third type of approach for evaluation, namely model-level constraints, consists in using a numerical simulation to correlate experimental data and physics-based model (Sause, 2016).

SECTION

Beyond feature engineering for AE interpretation

PARAGRAPH

Manual feature engineering (MFE) plays a central role in the pattern recognition chain implemented to interpret AE signals and has become a must-to-do step in AE interpretation.

Can we change the way in analysing AE signals by considering directly the raw signals and streaming?

This is the main question tackled in this publication.

Such an approach could potentially raise novel questions in terms of pattern recognition for AE signals and their interpretation.

This is also a way to progress towards automatic feature engineering and unsupervised representation learning from AE signals.

PARAGRAPH

Recent works questioning the use of features for unsupervised AE interpretation focused on source location (Holford et al., 2017; Chen et al., 2017a).

For instance, Chen et al. (2017b) uses dynamic time warping (DTW) to evaluate the similarity between AE signals for multi-source events localisation.

Distance-based approaches are indeed intuitive to solve the problem of unsupervised clustering directly from raw AE signals as done in time-series data mining (Fu, 2011; Zakaria et al., 2012; Morel et al., 2018).

Other approaches include information-theoretic novelty detection working directly on blocks of samples (Section 6 therein Pimentel et al., 2014; Martin-Del-Campo and Sandin, 2017; Chai et al., 2018; Del Campo et al., 2019).

PARAGRAPH

The closest related work to the present one is from Martin-Del-Campo and Sandin (2017).

They developed a sparse dictionary-based learning approach to analyse vibration signals.

The authors were interested in evidencing transition between healthy and faulty states in materials behaviour.

They first show how to train their model using “normal” condition vibration signals.

Likewise one-class supervised methods or baseline-based approaches (Farrar and Worden, 2013; Pimentel et al., 2014), the method is able to generate a novelty score reflecting how similar are the new unknown testing data compared to the normal conditions.

In their experiments, they collected acoustic emission data from a tensile quasi-static test on a stainless steel specimen.

They decomposed the streaming into segments of the same length and train the parameters on normal condition data corresponding to the phase where the material remains elastic.

They showed that their method is able to depict the transition between elastic and plastic phases.

This approach was extended in Del Campo et al. (2019) combining sparse dictionary-based learning with orthogonal matching pursuit to statistically represent a piece of AE streaming as a linear superposition of learned/optimised shift-invariant waveforms and Gaussian noise.

This approach is used to detect the contamination of the lubrication of bearings at different rotational speeds.

A training stage allows to represent the normal condition (uncontaminated lubrication) and during testing, the method generates a “rate of activation” (likewise a novelty indicator) of the learned waveforms according to the level of contamination.

SECTION

Contribution and paper organisation

PARAGRAPH

We propose a clustering methodology (described in Section 2) based on representation learning of raw AE signals (Fig. 1).

The key point is that it does not require manual feature extraction from AE signals and works directly on raw AE signals.

According to the terminology used in Liao (2005, Section 3.3 therein), the proposed method is model-based.

The idea detailed in the present paper was first published in Butaud et al. (2018) and Ramasso et al. (2019) with no mathematical details which are provided below together with new tests.

The approach is scalable for the analysis of a huge amount of AE signals, collected, for example, during fatigue tests as shown in experiments.

PARAGRAPH

Compared to the work of Martin-Del-Campo and Sandin (2017) and Del Campo et al. (2019), the streaming is summarised by a set of AE “hits” (as defined in the standard (Anon., 2019a)) with different lengths found out by a wavelet-based detector published in Kharrat et al. (2016).

The wavelets are not used as a standard filter, but rather as a trigger to determine the onset time of transient signals (wave-picking like for seismic data analysis).

It is applied on a streaming block-wise (with 250 Ksamples) to adapt the thresholds in the wavelet decomposition (Donoho, 1995).

PARAGRAPH

Many information processing tasks can be very easy or very difficult depending on how the information is represented (Goodfellow et al., 2016 Chap.

15).

So, the proposed approach is expected to better exploit the richness of the acoustic emission streaming by considering raw AE signals.

The approach consists in fitting a modified version of auto-regressive hidden Markov models onto randomly selected AE signals serving as references (Section 3).

Those models perform a decomposition of AE signals into a linear combination of auto-regressive models where the switching from a model to another is governed by a Markov chain.

As in reconstruction-based novelty detection (Pimentel et al., 2014), the obtained models are then used to generate novelty indicators (Section 4) when applied on newly observed AE signals.

PARAGRAPH

A consensus clustering (Section 5) is then developed to draw benefits from multifarious subsets of those indicators.

The clustering step exploits some ideas published in Ramasso et al. (2015) and Chandarana et al. (2018) about confidence intervals and about the evaluation criterion that gives preference to subsets evidencing regularly spaced-in-time clusters onsets.

This concept is represented on the top right-hand side of Fig. 1 depicting the cumulated occurrence of each cluster.

Accumulation depicts the onsets (well spread along the x-axis) and the kinetics (change of slope) which can then be used for monitoring purposes.

Finally, experimental results concern both simulated data (presented in Section 6) and real data from composite materials in quasi-static and fatigue tests (in Section 7).

PARAGRAPH

Compared to Martin-Del-Campo and Sandin (2017) and Del Campo et al. (2019), we do not perform anomaly detection in the classical sense.

Indeed, anomaly detection requires a baseline to train a one-class supervised learning algorithm which can then be used for online monitoring (Farrar and Worden, 2013; Pimentel et al., 2014).

In our methodology, we are concerned by offline clustering.

For that, a few AE signals are randomly picked in a dataset and used to estimate the parameters of various auto-regressive hidden Markov models.

The random selection makes this method unsupervised and the repetitions allow to build confidence intervals on the chronology of onsets of damages estimated at the end of the algorithm.

The quality of the chronology of onsets of clusters is exploited by the clustering algorithm to select some of the randomly picked signals.

It is similar to the final step of standard clustering methods used in AE literature which usually depend on a quality criterion reflecting the compactness and separability of clusters (Section 1.1.3).

Conclusively, there is generally a kind of supervision in AE clustering since a “supervision signal” (Goodfellow et al., 2016 Section 5.1.3 therein) is used to select the most appropriate parameterisation of the clustering method (such as the inputs and the number of clusters).

SECTION

PARAGRAPH

Methodology and problem statement

PARAGRAPH

An AE signal is a collection of real values (voltage) xt∈ℜ defined at discrete time t which can be mathematically represented by a function f(x;θ) with parameters θ.

We here suppose that f includes an autoregressive model which allows to compute a value xt from previous values xt−δ,δ=1…Δ.

In that way, function f, estimated from a reference AE signal, can be used on new observed AE signals in order to compute a prediction xˆt for each t.

Given the observed AE signal and the prediction through its representation f, we can compute novelty scores that evaluates the similarity between the observed and reconstructed AE signals.

For instance, the mean squared error (MSE) can be used: NOVmse(i)=1Ti∑t=1Ti(xˆt−xt)2where Ti is the length of the current AE signal.

The global problem tackled in this work can thus be decomposed as follows:

PARAGRAPH

Each problem is tackled in the following sections.

The methodology is pictorially illustrated in Fig. 1.

SECTION

ARWHMM for building the model of an AE reference signal

PARAGRAPH

In this section, we describe a method to solve problem 1 using ARWHMM.

SECTION

Representing AE signals using ARWHMM

PARAGRAPH

In an ARWHMM model, a measurement at time t, xt is mathematically represented as a weighted sum of the previous measurements plus an error term where the weights are defined conditionally to hidden states of a Markov process: xt=−∑δ=1Δrδ(yt)⋅xt−δ+ϵt(yt),1≤t≤Twith yt∈Ω={ω1,ω2,…ωK} is the value of the state at time t, and where the noise term ϵt(yt)∼N(0,σ(yt)) has a covariance σ(yt) depending on the state.

The AR coefficients for the ith state are denoted as r(i) and B=(r(1);…;r(i);…;r(K)) is the matrix of all AR coefficients.

The state may represent an internal variable with or without physical meaning.

The weights and the stochastic switching between AR models are governed by a Markov chain and are automatically learned from data using maximum likelihood (Chiang et al., 2008; Juesas et al., 2016).

The switching between internal states is governed by the Markov chain represented by a transition matrix A with elements aij=p(yt=j|yt−1=i) (probability of going into state j at time t given the state was i at t−1).

The prior probability of the chain is denoted as Π=[π1…πK], where πi is the probability to be in state i at time t=1.

The set of parameters to estimate is λ=A,Π,B,Σ,1≤i≤K where K is the number of internal states in the ARWHMM.

SECTION

Learning parameters in ARWHMM

PARAGRAPH

Learning can be performed in the Expectation–Maximisation (EM) framework (Dempster et al., 1977).

In the E-step, we evaluate the expectation of the hidden variables given the data; In the M-step, the auxiliary function Q representing the expectation of the complete-data loglikelihood has to be maximised to ensure that the likelihood will not decrease at each iteration, Q(λ,λ(q))=Eλ(q)[log(L(λ;z))|x,w]=∑yp(y|x,λ(q))⊕w(y)logL(λ;z)with (q) the iteration index of EM algorithm, x is the dataset (here represented by the AE reference signal), and z=(x,y).

Operator ⊕ is a point-wise multiplication followed by a normalisation (Patil, 2002; Denoeux, 2013).

Variable w(y) represents a prior on hidden variables (for example distributions over possible internal states given AE signals).

It offers the possibility to adjust parameters estimates (Denoeux, 2013; Ramasso and Denoeux, 2014).

PARAGRAPH

The complete-data likelihood function is given by L(λ;z)=p(y1;Π)∏t=2Tp(yt|yt−1;A)×∏t=1Tp(xt|yt;r(yt),σ(yt))where the dependence to the parameters of the model is made explicit.

We define the likelihood as (Chiang et al., 2008) p(xt|yt,r(yt),σ(yt))=N(xt+∑δ=1Δrδ(i)⋅xt−δ∣0,σ(yt))that will also be represented for short as bt(i).

Using Eq. (4) in Eq. (3), we can expand the expression of Q, set the derivatives with respect to each parameter to zero to get the parameters at iteration (q+1) of EM, yielding the following updates for the Markov chain: πi(q+1)=γ1(i)(q)aij(q+1)=∑t=2Tξt−1,t(q)(i,j)∑t=2T∑l=1Kξt−1,t(q)(i,l),  where γ and ξ are the posterior probabilities computed using the forward–backward algorithm initially defined for Hidden Markov Models (Rabiner, 1989).

We remind below the forward pass which is useful to evaluate the likelihood of the ARWHMM model that will be used subsequently as a novelty score.

The forward pass recursively evaluates the forward variable αt(i) which is the probability of jointly observing the sequence up to t (for instance, the voltage values for an AE hit) x1,x2…xt and observing state i given prior knowledge: α1(q)(i)=π(q)(i)b1(q)(i)w1(i)αt(q)(j)=bt(q)(j)wt(j)∑iαt−1(q)(i)aij(q)  The likelihood of the observed data given the model is then L(λ(q);x,w)=∑i=1KαT(q)(i)Practically, given a set of parameters λ representing an ARWHMM built from a given transient, the value of L(λ;xtest,w) evaluates how good is the fitting of the learned model λ on a new transient xtest.

This similarity measure will be discussed with others subsequently.

PARAGRAPH

For the observation model, the noise covariance update is (Chiang et al., 2008): Σi(q+1)=1∑t=1Tγt(q)(i)∑t=1Tγt(q)(i)[xt+∑δ=1Δrδ(q)(i)xt−δ][xt+∑δ=1Δrδ(q)(i)xt−δ]′and the expression of the AR coefficients B(q+1)(i) are B(q+1)(i)=−[∑t=2Tγt(q)(i)xtut−1′][∑t=2Tγt(q)(i)ut−1ut−1′]−1with ut−1=(xt−1,xt−2,…,xt−Δ)′.

SECTION

Setting hyper-parameters

PARAGRAPH

The sample partial autocorrelation was used to find the order (Δ) of each AR model.

It assumes that an AR(p) process can be described in terms of p nonzero functions of the autocorrelations (Box et al., 2015 Chap.

3), plotted against Δ=1,2…p…Pmax.

The plots presents a cutoff after lag p if the process is a pth-order autoregressive one.

If the process is autoregressive of order p and the time-series of length N, the estimated partial autocorrelations of order p+1, and higher, are approximately independently and normally distributed with zero mean and standard error equal to 1∕N (Box et al., 2015 Eq. 6.2.3).

PARAGRAPH

The weights w can play different roles, one being the possibility to incorporate domain knowledge (e.g. from physics of mechanical waves or from damage progression) in the training and testing phases (Vannoorenberghe and Smets, 2005; Côme et al., 2009; Ramasso and Denoeux, 2014; Zhou, 2017) or the novelty detectors.

Domain-based novelty detection approaches (Pimentel et al., 2014) allow to define a boundary on the structure of the training dataset.

Then, new measurements are compared to the boundary instead of the density for classical approaches.

For the remaining of the paper, the weights were set to 1 (likewise prior information are unavailable) and the tuning of those parameters is let for future work.

SECTION

Implementation details and complexity

PARAGRAPH

It can be observed that the posterior probability γ plays an important role (used in all updating equations).

We can thus apply first a partially hidden Markov model (PHMM) (Ramasso and Denoeux, 2014) (the code is available on Matlab© central) over the data made of {[xt−1xt−2…xt−Δ]}t=1T.

This algorithm provides a first estimate of γ without taking into account the AR process in each state.

This first estimate can be used to compute all parameters of the ARWHMM.

The advantage of the PHMM is that it also manages prior information on states likewise the ARWHMM.

PARAGRAPH

The second important issue concerns the possibility that the likelihood (Eq. (5)) may not be defined when applying a model to a new AE signal.

It can appear that some new data (used in test for example) may be very different to the data used in model learning.

In that case, the likelihood may be close to 0.

An AE signal for which no ARWHMM model is able to generate a likelihood in Eq. (5) is an information about the fact that the set of models is not sufficient to represent the range of possibilities in a dataset.

In that case, it is required to add more AE signals during the training phase.

PARAGRAPH

Thirdly, to our experience, it is relevant to incorporate the mean and the variance of the AE signal used during the training of a model λ as a part of it.

Therefore, prior to performing the inference phase (generating the novelty scores) using a model λ on an unknown AE signal, this signal is z-normalised by simply removing the mean and dividing by the variance of the AE signal used to estimate the parameters in λ.

PARAGRAPH

Finally, in terms of computational complexity, the main operations are made during calls to both the forward and backward propagations of probabilities, each implying about N⋅K2 operations for K states and a signal with N points.

Those exact (optimal) propagations are thus easily computed.

The inference stage (to compute the predicted output) involves only a forward pass.

SECTION

Estimating novelty scores

PARAGRAPH

In this section, we show how to extract novelty scores from an ARWHMM λ in order to solve problem 2.

The measures are available in Matlab©.

Each score NOV•(i) for a given novelty score (• will be replaced by an acronym subsequently) is indexed by a variable i which represents the value of the scores for the ith AE signal collected (the order of AE signals is respected according to the acquisition).

The ith AE signal is denoted xi=[xi1,xi2…xiTi] with length Ti.

The scores are calculated using two information: the input AE signal xi (to be analysed) and the approximation made by a model λ and denoted xˆi.

The set of scores form a matrix used in the next section for clustering.

This matrix is also called distance map in the unsupervised shapelets framework (Zakaria et al., 2012).

SECTION

Measure 1: Mean-squared error (MSE)

PARAGRAPH

The mean squared error (MSE) between the input AE signal (xi) and its approximation (xˆi) made by the ARWHMM, divided by its length (Ti), NOVmse(i) is given by Eq. (1).

SECTION

Measure 2: Loglikelihood (LOGL)

PARAGRAPH

The loglikelihood is the sum of the elements in the forward variable at time Ti after applying the model λ on the input AE signal (xi).

This probabilistic score, NOVlogl(i) and defined in Eq. (8), does not require the approximation xˆi since it directly quantifies the fitting of the model on the input AE signal.

SECTION

Measure 3: Peak signal-to-noise ratio (PSNR)

PARAGRAPH

The peak signal-to-noise ratio (PSNR) takes the number of bits per sample used to encode AE signals.

It is defined as NOVpsnr(i)=20log10(2nb−1NOVmse(i))where nb is the number of bits per sample (depending on the acquisition board, for instance 16 bits in standard AE system).

The number of bits remaining constant, it should not perform better than MSE as confirmed by later results.

SECTION

Measure 4: Maximum absolute squared deviation (MAXERR)

PARAGRAPH

The maximum absolute squared deviation (MAXERR) of the original signal (xi) from its approximation (xˆ) is defined as NOVmaxerr(i)=maxt|xˆit−xt|

SECTION

Measure 5: Ratio of the squared norm (L2RAT)

PARAGRAPH

The ratio of the squared norm of the signal approximation (xˆ) to the input signal (x) is denoted L2RAT and is defined as NOVl2rat(i)=∑txˆt2∑txt2

SECTION

Measure 6: Non dimensional error index (NDEI)

PARAGRAPH

The ratio of MSE to the standard deviation of the target (std(xi)) is called non dimensional error index (NDEI) has been used in the past for evaluating the quality of predictions in neuro-fuzzy systems (Angelov and Filev, 2004): NOVndei(i)=NOVmse(i)std(xi)

SECTION

Clustering approach

PARAGRAPH

This section bring a solution to problem 3 to 5.

PARAGRAPH

In clustering, two important problems must be faced: Feature selection and estimation of the number of clusters.

Novelty scores N=[NOVmse′NOVlogl′NOVpsnr′NOVl2rat′NOVmaxerr′NOVndei′] for all AE signals collected constitute the training data.

All the possible subsets can be considered as potential inputs of the clustering method.

In this paper, each single novelty indicator, all pairs and the first order difference of the indicators were considered as potential subsets of features for the Gustafson–Kessel clustering method (Gustafson and Kessel, 1978).

For each subset of features, one partition is obtained.

All partitions (one per subset) were then sorted as follows.

For each partition, the time onset of each cluster was determined.

This onset is obtained by taking the time stamp of the AE signal corresponding to the first occurrence of a cluster.

Then, each cluster was re-labelled according to their order of occurrence: the first cluster to occur was labelled “1”, the second cluster labelled “2”, and so on.

This co-association allows the fusion of partitions since all clusters with the same label are assumed to correspond to the same source.

This process was suggested first in Ramasso et al. (2015).

After re-labelling, each partition was ranked according to the following criterion (Chandarana et al., 2018): C(S)=∑k=1κ−1Δonset(k,k+1)logΔonset(k,k+1)Δonset(k,k+1)=tonset,k+1−tonset,k  where κ is the number of cluster, S⊆N is a subset of novelty scores (single, pairs and derivatives) used to compute the partition, tonset,κ+1 is equal to Ti which is the duration of the ith AE signal.

This criterion assumes that the onsets of all clusters in a given partition should be spread onto the time (or load) axis as uniformly as possible.

When clusters are spread, it means that the corresponding AE sources are activated gradually, and this will help to better understand the damage kinetics compared to when all clusters start too closely and too early in the test (Placet et al., 2013; Ramasso et al., 2014).

PARAGRAPH

Once the partitions have been sorted according to this criterion, the 15 best partitions were selected.

The fusion process of those partitions works as follows.

For all partitions selected, the logarithm of the cumulated occurrence of the ith cluster is plotted against time (or load) (Ramasso et al., 2015).

When superimposed on the same graph, the supremum and infimum of this set of curves define an envelope evolving with time.

It represents the time-dependent uncertainty of each cluster.

The centreline of the envelope is defined by the median of the logarithm of the cumulated occurrence from the 15 best partitions selected.

This process is performed by varying the number of clusters.

For every value of the number of clusters, the quality of the partition obtained by the fusion process is evaluated by using a bootstrapped ensemble method with the computation of the normalised mutual information (Fred and Jain, 2005).

This method finds the natural number of clusters which maximises the robustness of the clustering results against change in the input partitions.

In other words, by removing some partitions, a robust method must give a similar fusion result which is ensured using this criterion.

The fusion process is pictorially illustrated in Ramasso et al. (2015) using composite rings and in Chandarana et al. (2018) and Chandarana (2019) using tubular composite structures.

SECTION

Controlled experiments

SECTION

Description of the dataset

PARAGRAPH

We here propose a toy dataset to generate transients signals and inspired from Au and Beck (2001).

We suppose that an AE signal of length T is made of a set of T spikes, where each spike is the response of a resonant second order model to a Dirac excitation with random amplitude E: R(s)=11+2ζkωks+s2ωk2Ewhere s is the Laplace variable, k represents the class number, parameterised by ωk and ζk.

In our case we considered 4 classes, i.e. 4 types of AE signals with ω1=75 rad/s, ω1=50 rad/s, ω1=30 rad/s, ω4=20 rad/s, and ζ1=2%, ζ2=5%, ζ3=20%, ζ4=35%.

Algorithm 1 is applied to generate transients.

Several random sampling steps are used to increase the difficulty of modelling the time evolution of each signal.

The goal is to discriminate the classes according to raw signals and to demonstrate that the proposed method is able to capture both the frequency content and the time evolution without feature extraction using ARWHMM.

The performance of clustering methods has been evaluated using the Adjusted Rand Index (ARI) (Vinh et al., 2009).

The value is between 0 (bad clustering) and 1 (perfect clustering).

PARAGRAPH

A set of 100 signals per class have been generated, and all normalised between [−1,1].

Fig. 2 depicts a typical signal for every class.

The number of samples (6000) was selected sufficiently high to show the applicability of the method to work on real data with sampling around 5 MHz.

It is indeed close to typical AE signals duration (material dependent feature) found in AE literature, for example (Fig. 1-3 Lopez Pumarega et al., 2003; Fig. 6b Gabrion et al., 2013; Tab. 2,3 Sibil et al., 2012).

The ARWHMM can be parameterised to fit AE signals with relatively arbitrary length by increasing the number of hidden states or the predictors in AR models.

SECTION

PARAGRAPH

Results

PARAGRAPH

Fig. 3 depicts the sample partial autocorrelation for Δ=1…100.

We can observe a first cutoff around p=5, then around p=10 and p=20.

The lowest value (thus less parameters), p=5, was used by expecting a better generalisation of the model to unknown case.

PARAGRAPH

A PHMM was used to initialise the ARWHMM using 2 states and 10 Gaussian components per state for observations modelling and was run 10 times with random initialisation to select the likeliest model.

The model was trained on signals from class 4 drawn randomly for the illustrations below (tests have been done with arbitrary signals from classes 1, 2, 3 and 4 with similar conclusions).

PARAGRAPH

Three clustering methods from the literature (implemented in Matlab©) were applied on each single novelty score: Kmeans (KM), Gaussian Mixture Model (GM) and agglomerative hierarchical cluster tree (LK), each with 2 to 6 clusters.

The optimal partition was selected automatically using three types of quality indices from the literature focusing on clusters’ shape: Calinski–Harabasz (CH), Silhouette (SIL) and Davies–Bouldin (DB).

It led to 9 combinations, each with a given marker in Fig. 4.

PARAGRAPH

L2RAT novelty score yields the exact number of clusters (equal to 4) in all combinations and with correct assignment of clusters for all classes.

This result, obtained using only one AE signal and one novelty score, shows that the method is able to reveal the true data structure automatically independently of the clustering method or the quality index.

CH index generally overestimated the number of clusters on this dataset (the performance is not much less than others since clusters were split and with no mixing between clusters).

The SIL and DB indices generally underestimated the number of clusters for all clustering methods with MSE or NDEI novelty scores (with mixing between clusters).

PARAGRAPH

The residual error along time is plotted in Fig. 5 (at each time step as well as the cumulated value).

It is estimated by the ARWHMM trained on an AE signal from class 4 and applied on AE signals from the four classes.

We can observe how the error evolves gradually as new data points are collected.

The responses are naturally ordered as class 4  ≽ class 3  ≽ class 2  ≽ class 1 (natural due to the damping and natural frequency of signals).

PARAGRAPH

Sensitivity to the AE signal used in training: Fig. 6 shows the sensitivity of the method according to the selection of the initial AE signal used in training for the toy dataset. 20

signals were randomly selected from all classes independently.

We can observe a first set of results, with novelty score L2RAT: Results are stable with an ARI equal to 1 (recognition of all 399 signals for every test), and 0.9 with CH index coupled with KM and LK clustering methods.

CH index coupled with various methods and novelty scores then provide a second set of results varying from 0.6 to 0.3 with more variability.

Then the third set of results are made of configurations (novelty score, index, clustering) which provide low performance.

PARAGRAPH

Comparison with supervised classification: Since the ground truth is known (by simulation), we can evaluate the performance that can be obtained using supervised learning.

For that, we used random subspace ensembles implemented in Matlab© 2016.

The input was the set of 6 novelty scores generated by an ARWHMM trained on one signal from class 4 and applied on the remaining 399 signals.

Fig. 7 shows the results using a 2-NN classification learner.

The performance is plotted against the number of learners (1…15) in the ensemble and using 10-fold cross validation.

We can observe that the classification error rate of this supervised learning method oscillates around 16% with at least 10 learners.

With one learner, the error is about 18.5% which is greater than the proposed method using L2RAT (no error and correct estimation of the number of clusters despite using one AE signal from a unique class).

PARAGRAPH

Comparison with supervised novelty score selection: Using supervised learning, we can also evaluate if the relevance of novelty scores as seen by the ARWHMM (L2RAT ≽ NDEI ≽ MAXERR ≽ LOGL ≽ MSE ≽ PSNR), is similar to supervised learning.

The variable selection method based on neighbourhood component analysis (Yang et al., 0000) implemented in Matlab© 2016 was used.

We can observe that L2RAT (Fig. 8) is indeed the far most important novelty score for this dataset.

This supervised method also emphasises that the worse scores for this particular dataset are MSE and PSNR are underlined in our method (Fig. 6).

Therefore, using only one unique signal, the proposed unsupervised learning method based on ARWHMM here provides quite similar results.

SECTION

Real dataset

PARAGRAPH

We considered AE signals generated during a quasi-static and a fatigue tests of laminated composite materials.

Such materials are extensively used in aerospace industry due to their high specific strength and modulus.

Their behaviour under impact is of paramount importance since impacts occurring during in-service use induce internal damages which are visually imperceptible but significantly trending the performance downward and possibly causing unstability in the structure (Abrate, 1998; Shi et al., 2016).

PARAGRAPH

SECTION

Materials and methods

SECTION

Materials and production of composite plates

PARAGRAPH

Carbon fibre reinforced laminates are based on Arovex© 250 Prepreg, which is a curing epoxy prepreg.

Samples were fabricated by autoclave forming with a curing cycle under a pressure of 3.5 bar, heating step with a rate of 1.5 °C/min to reach 121 °C, hold for 120 min, subsequent cooling step with a rate of 1.5 °C/min.

Vacuum was applied during the whole cycle.

A quasi-isotropic stacking sequence with 32 plies ([0∕±45∕90]4s) has been manufactured and investigated.

SECTION

Impact testing

PARAGRAPH

Impact tests were performed using an instrumented drop tower (Instron/CEAST 9340) equipped with an hemispherical steel impactor having a diameter of 12.7 mm.

A circular sample holder with an inner diameter of 40 mm was used to support the specimen, in combination with a clamping plate – pneumatically activated – having the same inner diameter (requirements of the ASTM D5628 standard).

Specimens have been tested at room temperature with an energy level of 2.5 J using a total mass of 2.987 kg.

After impact, some specimens were scanned using a nano-micro-tomograph to evidence the initial state of damage.

The cross-section view (Fig. 9) depicts a typical cone-shaped profile of defects initiated by the impact occurring at the top.

Interply delaminations are clearly visible (horizontal lines in white) at the interface between plies.

Through the thickness, the state of damage is evidenced.

Matrix cracks can also be observed (oblique lines between plies).

This network of delaminations is interlinked by intralaminar matrix cracks (Borstnar et al., 2016).

It was observed by Borstnar et al. (2016) that intralaminar matrix cracks occurred parallel to the direction of the fibres and form a “spiral staircase” of delaminations around the impact site.

During the following flexural tests, this complex initial state of damage will be the source of stress concentrations.

Matrix cracks for example represent the initiation points for new delaminations and fibre breakages which ineluctably change the performance of this type of material.

SECTION

PARAGRAPH

Flexural testing

PARAGRAPH

Both static and fatigue tests were performed using a four point bending device (ASTM D 7264) with a support span of 130 mm and a load span of 65 mm.

The tests were carried out in displacement control with a crosshead speed of 1 mm/min for the quasi-static tests.

This device was connected to an electro-mechanical testing machine.

Instron Eletropuls E10000, equipped with a 10 kN load sensor.

The displacement was measured by a LVDT transducer.

The fatigue tests were done under a sinusoidal waveform loading at 3Hz.

A load amplitude control mode and a ratio between minimum and maximum stress (R) of 0.1 were used with 80% of the maximum stress.

Peak-to-peak and average amplitudes of load and LVDT sensors were recorded for each cycle.

A complete cycle was also recorded as a function of a linear progression.

The last 20 cycles before breaking were also systematically recorded.

SECTION

Post-mortem analysis

PARAGRAPH

The impact loading, due to the low energy level used, resulted in a slight indentation on the impacted side while no damage was detected on the rear face.

Despite this apparently low level of damage, the specimens subjected to fatigue loading after impact exhibited a different failure pattern with extensive cracks and delaminations on both sides (Fig. 10), namely the one in compression and the other in tension.

In this case, multiple delaminations of the surface plies, starting from matrix cracks likely induced by the impact loading, caused a lost in integrity during their propagation at increasing load until catastrophic fibre failure occurred in the compression side.

SECTION

PARAGRAPH

AE acquisition

PARAGRAPH

The transient elastic waves were recorded during test at the material surface using a multichannel data acquisition system from Euro Physical Acoustics corporation (MISTRAS Group).

Two miniature piezoelectric sensors (micro-80) were used with preamplifiers set to 40 dB, a 20–1000 kHz filter and a sampling rate of 5 MHz.

The calibration was performed before each test after installation of the transducers on the specimen and using a pencil-lead break procedure.

The real-time wavelet-based wave picking method proposed in Kharrat et al. (2016) was applied to get AE signals with Dauchechies wavelet of order 10 and with detection thresholds set to PDT =  30μs, HDT =  100μs, HLT =  30μs.

SECTION

Clustering for quasi-static data

PARAGRAPH

Seven AE signals were selected randomly in the set of AE signals with amplitude greater than 60 dB (Fig. 11).

Then, every AE signal, used both in training and in testing, were normalised between −1 and 1 by dividing the voltage value by the maximum absolute value (∀t∈1…|x|,xt←xt∕maxt(|xt|)).

PARAGRAPH

On each AE signal, one ARWHMM was trained and the inference of the six novelty scores was then made on all other signals (this process was repeated for the seven signals).

The ARWHMM was initialised as in the previous section.

The number of states and components in the mixture model were kept to 2 and 10 as previously.

The lag was set for each signal using the same procedure as before based on sample partial autocorrelation.

For a given AE signal used in training, all novelty scores and all pairs in N=[NOVmse′NOVlogl′NOVpsnr′NOVl2rat′NOVmaxerr′NOVndei′]as well as in the first order difference of the scores, were used as inputs of clustering approach detailed in the previous section.

PARAGRAPH

Fig. 12 represents the result of clustering for the quasi-static test using the logarithm of cumulated occurrences in each cluster.

Each step represents the sudden assignment of AE signals to a cluster.

The number of AE signals assigned depends on the height of the step.

A plateau for a given cluster illustrates that the AE source associated to this cluster is not active.

The cumulated energy (absolute and MARSE Kattis, 2017) were extracted from AE signals and plotted here for information but not used in clustering.

The stress in the outer layer of the composite is also depicted.

This type of information is useful to understand the global behaviour of the material.

The drops observed in this curve are an indication of dramatic change in the stiffness due to fibre breakage and large damage propagation (matrix cracking, delamination, fibre/matrix debonding).

PARAGRAPH

The clusters’ onset are positioned close to the highest steps occurring on the cumulated energy (t=15,17,22,290,390 and 730s).

Therefore, without using any energy-based features, the method is able to infer some useful patterns concerning damage kinetics and corresponding to changes in the evolution of the energy features (De Rosa et al., 2009; Silversides et al., 2013; Maillet et al., 2014).

Those onsets, well spread on the time axis and optimised in the clustering method described beforehand, are useful to determine the various phases of the damage process.

Between phases, there is a stable damage growth and those phases may correspond to different damage mechanisms such as matrix cracking, fibre-matrix debonding, delamination, and fibre breakage, or similar damages but in different plies of the composite.

In that case, the cumulated occurrence graph shows that there may be dominating damages at different periods.

For instance, clusters 1–3 evolve drastically at the beginning of the test, while clusters 4, 5 and 6 only start at t=290,390 and 730s respectively.

The occurrence of cluster 5 is just after a period where clusters 2–4 remains quiet while cluster 1 evolves substantially.

The evolution of cluster 5 is also substantial between t=390 to t=730 compared to the other clusters.

SECTION

PARAGRAPH

Clustering for fatigue data

PARAGRAPH

A set of 10 AE signals were drawn randomly and used for training ARWHMM.

Each model was then applied on all AE signals in order to generate the novelty scores.

Fig. 13 represents the result of clustering.

We can observe that the method estimated 6 clusters with different onsets and kinetics yielding 5 main phases.

PARAGRAPH

In phase 1 (0%–33%), cluster 1 starts early (first cycles) with about 30 events (101.5) in the same clusters.

It evolves drastically until 20% and then follows a quiet period until first occurrence of cluster 2 with about 60 events.

This new cluster is synchronised with a high increase of cluster 1 together with a high increase of energy in AE signals.

During the second phase, cluster 2 quickly reaches a plateau which probably means that this cluster is related to a sudden progression of cracks.

The plateau for cluster 2 represents about 30% of the fatigue life during which only cluster 1 evolves quite linearly.

Phase 3 starts at 65% of the fatigue life, with the evolution of cluster 2 (end of plateau) which is then followed by the first occurrence of cluster 3 (with about 16 events), synchronised again with a substantial increase of the energy.

In phase 4, cluster 2 evolves substantially followed by the occurrence of cluster 5 (about 10 events) and a high increase of energy release.

Ultimate failure is preceded by the occurrence of cluster 6 and a huge increase of energy.

PARAGRAPH

Cluster 2 seems to drive several clusters and thus several damage mechanisms.

The evolution of this cluster around 65% of the fatigue life, preceding the evolution of energy and the occurrence of other clusters, is related to observations made by previous authors for other materials and different configurations (Momon et al., 2010; Maillet et al., 2012; Doan et al., 2015).

SECTION

PARAGRAPH

Conclusion

PARAGRAPH

This work shows how to use novelty detection for clustering raw acoustic emission signals.

This new approach does not need to extract features that represents a cumbersome phase when implementing a pattern recognition method to learn from those signals.

This paves a new way for the interpretation of acoustic emission streaming using representation learning.

PARAGRAPH

The method was applied on simulated data and compared to supervised learning.

The results shown that the proposed unsupervised approach is able to sort correctly the novelty scores according to their effectiveness in clustering this dataset.

It also performed well in clustering the full dataset using only one signal as a reference.

PARAGRAPH

When applied on real datasets originating from carbon fibre reinforced plastics composites, results shown relevant clustering in terms of timeline of the obtained clusters.

The onsets of the obtained clusters are well related to the evolution of the cumulated energy, which is a widely used feature to understand the behaviour of materials using acoustic emission.

This results shows that the proposed method is able to naturally capture this evolution without using this feature.

The change points obtained by the proposed method are also well correlated with the evolution of the material properties both in quasi-static and fatigue tests.

PARAGRAPH

Future work include the development of new novelty detection measures, the optimisation of the number of random AE reference signals to use, the incorporation of domain-knowledge information in the modelling (e.g. through the weights).

Another key point is to make the proposed methodology suitable for online monitoring and, for that, to include information about the operational conditions of the material of interest.